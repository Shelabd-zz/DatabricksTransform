{"cells":[{"cell_type":"code","source":["clientId = \"9e443dbb-73f2-4e20-bf4d-fffcd86cd926\"\nclientKey = \"1]1mmsSjBHe0PXzD8trcJsxWh.iOUa_/\"\ntenantId = \"fd89f191-166e-474f-a80f-af83c8f5e17e\"\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n           \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n           \"fs.azure.account.oauth2.client.id\": clientId,\n           \"fs.azure.account.oauth2.client.secret\": clientKey,\n           \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/\"+tenantId+\"/oauth2/token\"}\n\n# # Optionally, you can add <directory-name> to the source URI of your mount point.\ndbutils.fs.mount(\n source = \"abfss://rawdata@team9adls.dfs.core.windows.net/\",\n mount_point = \"/mnt/rawdata\",\n extra_configs = configs)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["import pandas as pd\n\nSales_Addresses_FP = \"/mnt/rawdata/cloudsales/dboAddresses.csv\"\nStreaming_Addresses_FP = \"/mnt/rawdata/cloudstreaming/dboAddresses.csv\"\n\nSales_Addresses_Raw = sqlContext.read.parquet(Sales_Addresses_FP)\nStreaming_Addresses_Raw = sqlContext.read.parquet(Streaming_Addresses_FP)\n\nSales_Addresses_Raw = Sales_Addresses_Raw.toPandas()\nStreaming_Addresses_Raw = Streaming_Addresses_Raw.toPandas()\n\nSales_Addresses_DF = [Sales_Addresses_Raw, Streaming_Addresses_Raw]\nCloud_Addresses = pd.concat(Sales_Addresses_DF)\n\nCloud_Addresses['CreatedDate'] = pd.to_datetime(Cloud_Addresses['CreatedDate'], errors='coerce')\nCloud_Addresses['UpdatedDate'] = pd.to_datetime(Cloud_Addresses['UpdatedDate'], errors='coerce')\n\nCloud_Addresses.AddressLine2 = Cloud_Addresses.AddressLine2.astype(str)\nCloud_Addresses.ZipCode = Cloud_Addresses.ZipCode.astype(str)\n\ndisplay(Cloud_Addresses)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["VanCustomers_FP = \"/mnt/rawdata/vanarsdell/dboCustomers.txt\"\n\nVanCustomers_raw = spark.read.json(VanCustomers_FP)\nVanCustomers_df = VanCustomers_raw.toPandas()\n\nVanAddresses = VanCustomers_df[['CustomerID', 'AddressLine1', 'AddressLine2', 'City', 'State', 'ZipCode', 'CreatedDate', 'UpdatedDate']]\n\nVanAddresses['CreatedDate'] = pd.to_datetime(VanAddresses['CreatedDate'], errors='coerce')\nVanAddresses['UpdatedDate'] = pd.to_datetime(VanAddresses['UpdatedDate'], errors='coerce')\n\nVanAddresses.AddressLine2 = VanAddresses.AddressLine2.astype(str)\nVanAddresses.ZipCode = VanAddresses.ZipCode.astype(str)\n\nVanAddresses.insert(0, 'AddressID', 'None')\n\ndisplay(VanAddresses)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["CoffeeCustomers_FP = \"/mnt/rawdata/fourthcoffee/Customers.csv\"\n\nCoffeeCustomer_raw = spark.read.csv(CoffeeCustomers_FP, header=True)\n\nCoffeeCustomers_df = CoffeeCustomer_raw.toPandas()\n\nCoffeeAddresses = CoffeeCustomers_df[['CustomerID', 'AddressLine1', 'AddressLine2', 'City', 'State', 'ZipCode', 'CreatedDate', 'UpdatedDate']]\n\nCoffeeAddresses['CreatedDate'] = pd.to_datetime(CoffeeAddresses['CreatedDate'], errors='coerce')\nCoffeeAddresses['UpdatedDate'] = pd.to_datetime(CoffeeAddresses['UpdatedDate'], errors='coerce')\nCoffeeAddresses.AddressLine2 = CoffeeAddresses.AddressLine2.astype(str)\nCoffeeAddresses.ZipCode = CoffeeAddresses.ZipCode.astype(str)\n\nCoffeeAddresses.loc[CoffeeAddresses.AddressLine2 == 'nan', 'AddressLine2'] = 'None'\n\nCoffeeAddresses.insert(0, 'AddressID', 'None')\n\ndisplay(CoffeeAddresses)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["Cloud_Addresses['SourceSystem'] = '1'\nVanAddresses['SourceSystem'] = '2'\nCoffeeAddresses['SourceSystem'] = '3'\naddresses_frame = [Cloud_Addresses, VanAddresses, CoffeeAddresses]\n\nall_addresses = pd.concat(addresses_frame)\n\ndisplay(all_addresses)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["all_addresses = spark.createDataFrame(all_addresses)\nall_addresses.coalesce(1).write.mode(\"overwrite\").format(\"com.databricks.spark.csv\").option(\"header\",\"true\").csv(\"/mnt/rawdata/stagingdata/AllAddresses/\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":7}],"metadata":{"name":"TransformAllAddresses","notebookId":730143685605713},"nbformat":4,"nbformat_minor":0}
